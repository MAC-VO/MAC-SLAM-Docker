# System-level configuration are the same for all develop services
x-common-config: &common-config
  hostname: ${HOSTNAME}-dev
  volumes:
    - ../../:/workspace
  working_dir: /workspace
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
  stdin_open: true
  tty: true

  # For profiliing in a Docker container
  cap_add:
    - SYS_ADMIN
  privileged: true
  
  # For potential connection with Zed stereo camera
  devices:
    - "/dev/video0:/dev/video0"
    - "/dev/video1:/dev/video1"

  # Sufficient IPC shared memory for PyTorch as instructed in NVIDIA container.
  ipc: host
  ulimits:
    memlock:
      soft: -1
      hard: -1
    stack: 67108864

  # Auxilary environment variables
  environment:
    - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    - NVIDIA_VISIBLE_DEVICES=all
    - PYTHONUNBUFFERED=1

# Per-resource configuration service.
services:
  linux-cuda12-dev:
    <<: *common-config
    image: macslam/mac-slam:linux-cu128
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: "nvcr.io/nvidia/pytorch:25.06-py3"

  linux-cuda13-dev:
    <<: *common-config
    image: macslam/mac-slam:linux-cu130
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: "nvcr.io/nvidia/pytorch:25.08-py3"

  github-action:
    image: macslam/mac-slam:github-action
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: "nvcr.io/nvidia/pytorch:25.06-py3"

    volumes:
      - ../../:/workspace
