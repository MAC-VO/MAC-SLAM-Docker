# System-level configuration are the same for all develop services
x-common-config: &common-config
  hostname: ${HOSTNAME:-macslam}-dev
  volumes:
    - ../../:/workspace
  working_dir: /workspace
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
  stdin_open: true
  runtime: nvidia
  tty: true

  # Expose network port for rerun visualizer
  ports:
    - "9876:9876"

  # For profiliing in a Docker container
  cap_add:
    - SYS_ADMIN
  privileged: true
  
  # For potential connection with Zed stereo camera
  devices:
    - "/dev/video0:/dev/video0"
    - "/dev/video1:/dev/video1"

  # Sufficient IPC shared memory for PyTorch as instructed in NVIDIA container.
  ipc: host
  ulimits:
    memlock:
      soft: -1
      hard: -1
    stack: 67108864

  # Auxilary environment variables
  environment:
    - NVIDIA_DRIVER_CAPABILITIES=all
    - NVIDIA_VISIBLE_DEVICES=all
    - PYTHONUNBUFFERED=1

# Per-resource configuration service.
services:
  linux-cuda12-dev:
    <<: *common-config
    profiles: ["amd64"]
    platform: linux/amd64
    image: macslam/mac-slam:linux-cu128-amd64
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: "nvcr.io/nvidia/pytorch:25.03-py3"

  linux-cuda13-dev:
    <<: *common-config
    profiles: ["amd64"]
    platform: linux/amd64
    image: macslam/mac-slam:linux-cu130-amd64
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: "nvcr.io/nvidia/pytorch:25.08-py3"

  jetson-thor-dev:
    <<: *common-config
    profiles: ["arm64"]
    platform: linux/arm64
    image: macslam/mac-slam:linux-cu130-thor-arm64
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: "nvcr.io/nvidia/pytorch:25.08-py3"
  
  jetson-orin-dev:
    <<: *common-config
    profiles: ["arm64"]
    platform: linux/arm64
    image: macslam/mac-slam:linux-cu126-orin-arm64
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BASE_IMAGE: "nvcr.io/nvidia/pytorch:25.03-py3-igpu"

    # Fix the libjpeg library problem for PyZed
    volumes:
      - ../../:/workspace
      - /usr/lib/aarch64-linux-gnu/tegra:/usr/lib/aarch64-linux-gnu/tegra
      - /usr/lib/aarch64-linux-gnu/libjpeg.so.8:/usr/lib/aarch64-linux-gnu/libjpeg.so.8

  test-type-jetson:
    profiles: ["arm64"]
    platform: linux/arm64
    image: macslam/mac-slam:linux-static-analysis-arm64
    working_dir: /workspace
    
    build:
      context: .
      dockerfile: Dockerfile.test-type
      args:
        BASE_IMAGE: macslam/mac-slam:linux-cu126-orin-arm64
    
    command: "pyright"
    volumes:
      - ../../:/workspace

  test-cfg-jetson:
    <<: *common-config
    profiles: ["arm64"]
    platform: linux/arm64
    image: macslam/mac-slam:linux-cu126-orin-arm64
    command: "pytest -m 'not local'"

  test-type:
    profiles: ["amd64"]
    platform: linux/amd64
    image: macslam/mac-slam:linux-static-analysis-amd64
    working_dir: /workspace
    depends_on:
      - linux-cuda12-dev
      - linux-cuda13-dev
    
    build:
      context: .
      dockerfile: Dockerfile.test-type
      args:
        BASE_IMAGE: "macslam/mac-slam:linux-cu128-amd64"
    
    volumes:
      - ../../:/workspace

  test-cfg:
    <<: *common-config
    profiles: ["amd64"]
    platform: linux/amd64
    image: macslam/mac-slam:linux-cu128-amd64
    command: "pytest -m 'not local'"

  dev-container-unified-entry:
    <<: *common-config

    image: ${DEV_IMAGE}
    platform: ${DEV_PLATFORM}
    container_name: macslam-unified-dev
    command: sleep infinity
